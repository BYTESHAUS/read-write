# Arteficial Intelligence - Much ado about  ... fussing?

Artificial Intelligence is a hot theme in 2023, again<sup>üòæ</sup>. 
Don't try to dodge - in my city "AI" and "ChatGPT" saturate the program of the summer digital festival (every other lecture names them).

Its pace must be so gigantic that some scientists, prominent software engineers, and tech leads [search for an emergency break](https://futureoflife.org/open-letter/pause-giant-ai-experiments/). Other up-to-date visions (besides too common) can be grouped by:

<details>
<summary><ins>&nbsp;Impressive and inspiring&nbsp;</ins></summary>
&nbsp;

* *Sundar Pichai*, Google CEO:\
"AI is the most profound technology humanity is working on today."
* *Jensen Huang*, CEO of NVIDIA:\
"Software is eating the world, but AI is going to eat software."
* MkCinsey & Company:\
"Generative AI‚Äôs impact on productivity could add trillions of dollars [annually]..."
* *Ray Kurzweil*, inventor and futurist:\
"By 2029, computers will have emotional intelligence and be convincing as people."
* _Giles Pendleton,_ executive director of NEOM ($500 billion project):\
"The linear city will be ‚Äúassembled‚Äù using artificial intelligence."
* [and how without him] *Elon Musk*, xAI startup founder:\
"The goal of xAI is to understand the true nature of the universe."

\__________________________________________
</details>

<details>
<summary><ins>&nbsp;Realistic and pragmatic&nbsp;</ins></summary>
&nbsp;

These required much more search than the quotes above ...

* *Ginni Rometty*, CEO of IBM\
"Some people call this artificial intelligence, but the reality is this technology will enhance us. So instead of artificial intelligence, I think we'll augment our intelligence."\
&nbsp;&nbsp;&nbsp;&nbsp;<sup>‚úã</sup>&nbsp;<sub>Notice the word *augment*, which can apply to the abacus, paper thesaurus, or supercomputers in the same context.</sub>

* _Christopher Nolan_, filmmaker, questioned about AI in a 2023 interview:\
"... the real world is, by definition, infinitely complex. ... And so, any digital simulation or technology that simulates, eventually, it always hits a particular limitation."

* _Michael Atleson_, Attorney, Federal Trade Commission, 27/Feb/2023:\
"Keep your AI claims in check."

\__________________________________________
</details>

<details>
<summary><ins>&nbsp;Philistine and unimaginative (as of mine)&nbsp;</ins></summary>
&nbsp;

* **AI Lab, ~1500s** (yes, AI)

![Faust vs. homunculus, engraving](../_rsc/_img/Homunculus.engraving.wiki.jpg)

* **Alchemy workshop, 2020s**

![Illustration of IT and AI](../_rsc/_img/ComputerScience-Intro(learncomputerscienceonline.com).jpg)

*&nbsp;<sub>Images are for illustrative purposes only and belong to the wiki and IMLO</sub>

\__________________________________________
</details>

## Intelligence

Neither philosophy nor exact sciences nor neurobiology can formulate _intelligence_, and its genesis (both individual and on the whole) is a bigger mystery. 
Digitalization speaks in clear definitions - and there are none.

Adepts of both the bright and dismal AI future readily assume its *self-knowledge/awareness* as a trivial matter of time. 
To either brew by itself in increasingly complex code bouillon or get all of a sudden [short circuited](https://www.imdb.com/title/tt0091949)<sup>:cinema:</sup>.

Digital tech effectively and reliably automates much of hard cogitative ops (where humans are prone to errors), but not unformalizable processes (abstraction, criticism, motivation) that may result in great breakthroughs in exact sciences.<sup>:art:</sup>

&nbsp;&nbsp;&nbsp;&nbsp;<sup>:art:</sup> <sub>In non-exact studies and art too, but it's not that evident.</sub>

## Materiality

<details>
<summary><ins>&nbsp;<b>Automated but improperly credited to AI:</b>&nbsp;</ins></summary>
&nbsp;
  
+ processing vast amounts of data in real-time, finding patterns there,
+ routine translation and text generation,
+ image/video on-the-fly filtering,
+ fast recognition of all kinds,
+ assisted mathematical proofs (impossible earlier without required computing powers),
+ tutoring (as coding assistance),
+ engines that can smash humans in intellectual sports (Stockfish in chess)

\__________________________________________ 

</details>
<details>
<summary><ins>&nbsp;<b>Expected from AI but unavailable</b>&nbsp;</ins></summary>
&nbsp;

- **First and foremost**, pass so-called _Turing_ test\
You can think up a _CAPTCHA_, which a motivated fellow will promptly pass but "AI" may only exhaust.
- Pick and prove any unsolved mathematical problem with all computing power in the world<sup>:scientist:</sup>
- Write a stronger chess engine

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>:scientist:</sup>&nbsp;<sub>Humans can do, as _Grigori Perelman_ with one of the seven _Millenium Problems_.</sub>

\__________________________________________ 
</details>

<details>
<summary><ins>&nbsp;<b>Hype and hoax</b>&nbsp;</ins></summary>
&nbsp;

- **First and foremost** AI is publicity for investors. That has nothing to do with progress and technology.
- There's human assistance behind many AI tricks (either individual tuning or "machine learning" by thousands in low-rate offshore).\
  (Do you remember machine learning of [Mechanical Turk](https://en.wikipedia.org/wiki/Mechanical_Turk)?)

\__________________________________________ 
</details>

## Conclusion

Some would regard *AI* as a buzzword rather than technology, or IntelliSteampunk vs. AI dystopia.

## Appendix. AI booms before

Grunting "again"<sup>üòæ</sup> obliges me to recall a few AI tides, impromptu and without wiki. I'd skip old fiction and the times when man humanized mechanical breakthroughs, and resume on the digital era.

### 1950s

The crucial IT decade ever - an energized rack of metals, glass, and vacuum could replace hives of handmade calculations, and scientists elaborated impressive HMIs with high-level languages. 

The leap in both hardware and software could surpass sci-fi fantasies. And there were two letters (not "AI") that made folks think that processors will soon be peers of human brains.

<details>
<summary><ins>&nbsp;These two letters were ...&nbsp;</ins></summary>
&nbsp;
  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**IF** -- This statement in high-level languages introduced the feeling of human doubt and decision-making.


\__________________________________________ 
</details>

### 1970s

Computers gradually spread from science calculations to business assistance, and robotics rendered funny androids. In chess, with its intellectual aura, computer programs could give winning hints that grandmasters couldn't discern and had attributed to the abrupt progress of their inferior opponents.

### Late 1980s - early 1990s

PCs have become a mass factor at work and home. Thousands of enthusiasts, fascinated by the power and ease of programming, along with top-level engineers, which one could hire then for symbolic rates, tried to reanimate AI. A side-effect of that kick discovered pseudo-sciences like _the theory of inventive problem-solving_.

And here we are in **2023**, when "_there will be no (human) programmers in five years_" (*Emad Mostaque*, CEO of Stability AI).

... ‚åõ LET'S RECAP AFTER FIVE YEARS :microscope:...

