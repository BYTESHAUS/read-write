# AI Twenties - Much ado about ... fussing?

In the heat records breaking mid-2020s _Artificial Intelligence_ is on trend again. Nobody will dodge this "IntelliSteamPunk" festival - __AI__ and __GPT__ are in every other lecture, article, or product release.

Torrents of news and announcements have urged prominent software engineers, scientists, and their leads to [think of a dam](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) against [AI&nbsp;dystopia](https://www.businessinsider.com/ai-extinction-risk-openai-deepmind-anthropic-ceos-sam-altman-2023-5), while other visions are:

<details>
<summary><ins>&nbsp;<b>Impressive mainstream</b>&nbsp;</ins></summary>
&nbsp;
 
* *Sundar Pichai*, Google CEO:\
"AI is the most profound technology humanity is working on today."
* *Jensen Huang*, CEO of NVIDIA:\
"Software is eating the world, but AI is going to eat software."
* MkCinsey & Company:\
"Generative AI‚Äôs impact on productivity could add trillions of dollars [annually]..."
* *Ray Kurzweil*, inventor and futurist:\
"By 2029, computers will have emotional intelligence and be convincing as people."
* _Gray Scott_, futurist, techno-philosopher, founder and CEO of SeriousWonder:\
  "There is no reason and no way that a human mind can keep up with an artificial intelligence machine by 2035."
* [and how without him] *Elon Musk*, xAI startup founder:\
"The goal of xAI is to understand the true nature of the universe." [no less]

\__________________________________________
</details>

<details>
<summary><ins>&nbsp;<b>Occasional pragmatism</b>&nbsp;</ins></summary>

* *Ginni Rometty*, former CEO of IBM:\
"Some people call this artificial intelligence, but the reality is this technology will enhance us. So instead of artificial intelligence, I think we'll augment our intelligence."

* *Larry Page*, Google co-founder:\
"Artificial intelligence would be the ultimate version of Google. ... Unfortunately, we‚Äôre nowhere near doing that now."\
[Well, it was in 2000]

* _Christopher Nolan_, filmmaker, questioned about AI in a 2023 interview:\
"... the real world is, by definition, infinitely complex. ... And so, any digital simulation or technology that simulates, eventually, it always hits a particular limitation."

* _Michael Atleson_, Attorney, Federal Trade Commission, 27/Feb/2023:\
"Keep your AI claims in check."

* _Sam Altman,_ [on/off] CEO of OpenAI, 04/Dec/2022:\
"i am a stochastic parrot, and so r u."&nbsp;<sup>ü¶ú</sup>\
[vs. _Arikia Millikan_: [Parrots are not stochastic and neither are you](https://www.content-technologist.com/stochastic-parrots/).]

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>ü¶ú</sup> <sub>The term Emily M. Bender _et al_ coined with "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?".</sub>

\__________________________________________
</details>

<details>
<summary><ins>&nbsp;<b>Philistine margins</b>&nbsp;</ins></summary>
&nbsp;

[![AI: 1523 vs 2023](../../../../_rsc/_img/memes/AI_medieval_now-spot_the_diff.jpg)](../../memes)

*&nbsp;<sub>Images are for illustrative purposes only and were taken from Wiki Commons and IMLO (learncomputerscienceonline.com)</sub>

\__________________________________________
</details>

## Stumbling block

Neither philosophy nor natural sciences can formulate _intelligence_. Its genesis, individual rise, and (un)consciousness behind are a bigger mystery. 
Digitalization speaks in precise definitions - and there are none.<sup>‚öôÔ∏è</sup>

Adepts of bright and heralds of dismal AI future readily assume its *self-knowledge/awareness* as a trivial matter of time. 
To brew by itself in increasingly complex code bouillon or get all of a sudden [short&nbsp;circuited](https://www.imdb.com/title/tt0091949)&nbsp;üé¶.

IT fantastically and reliably automates much of hard cogitative ops<sup>:coffee:</sup>, but not vague abstraction, (self-)criticism, motivation - which are precursors of great enlightenings in sciences and arts<sup>:art:</sup>.

&nbsp;&nbsp;&nbsp;&nbsp;<sup>‚öôÔ∏è</sup> <sub>Publicized views of decision-making as a relay work of neurons preset by acquired knowledge is an ingenuous simplism of free will debate.</sub>\
&nbsp;&nbsp;&nbsp;&nbsp;<sup>:coffee:</sup> <sub>Where humans are slow, prone to errors, lack parallelism, and finally get distracted, fatigued, or frustrated.</sub>\
&nbsp;&nbsp;&nbsp;&nbsp;<sup>:art:</sup> <sub>Fed with plain plots (keywords) bots may generate impressive video shorts, but it could be only a gifted artist who will weave a masterwork using this technique.</sub>

## Evidence

You can think up a **:canada:**:parking::razor::switzerland::a:, which a diligent person will untwist but Internet-connected AI-bot may only exhaust (unless you limit attempts). The same fellow may create unique text, image, or script that GPT will pick in search results to quote.<sup>üëì</sup>

The progress of computing powers allowed _assisted mathematical proofs_, which was impossible before. Artificial neural net of all the processors in the world wouldn't solve an open _mathematical problem_<sup>:1234:</sup>. Humans do.<sup>:scientist:</sup>

It was a unique supercomputer (IBM Deep Blue) that finally beat the world chess champion in 1997 - now it could be amateur freeware on a smartphone to discard. However, humanoid developers wrote C/C++ for their engines (up to _Stockfish_ and _Leela Chess Zero_), while AI can't generate a better one. 

IDEs and assists strongly boost dev productivity, but if any AI claims to write the code, it will be either a snippet or most rated Q&A or you need to describe the requirements closely to operators.

Driving is a vivid subject of automation, done almost to the whole extent ... and no _deus ex machina_ (aka Full Self-Driving) appeared to handle the modest remainder of less predicted hazards<sup>ü§ñ</sup>. And this is after opportunities to "learn" on millions of miles in real traffic with supervising drivers.

 _Supervised machine learning_, that nurtured the [Mechanical&nbsp;Turk](https://en.wikipedia.org/wiki/Mechanical_Turk), now shades significant human assistance and intervention backing many AI processes (individually by developers and by thousands in low-rate support).

 Enough contributors were stunned to know that their Q&A and imageboards supply chatbots with content under the agreement.

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>üëì</sup> <sub>Vice versa insert of generated or pasted content in "original" publications is predetermined to disclosure.</sub>\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>:1234:</sup> <sub>Conditions for many are plain and unambivalent enough to submit them as a clause to a chatbot.</sub>\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>:scientist:</sup> <sub>As _Grigori Perelman_ with one of the seven _Millenium Problems_ (announced in 2010).</sub>\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>ü§ñ</sup> <sub>Auto-pilot _level&nbsp;5_ is a decade still "next year", and brands like Uber drop multi-billion research. Not teathing problems.</sub>

> **Compare to hash functions on pure math, which had silently revolutionalized IT before the blockchain boom.**

## Conclusions

 ¬´AI¬ª overhypes potential IT and credits its groundbreaking products<sup>:hammer_and_wrench:</sup> with self-learning.
 
Protagonists put the synergism of natural intelligence<sup>üßë‚Äçüî¨</sup> on rising computing powers, and wrap it with HQ videos, splendid presentations, and cogent oration.

AI bots found their rich niche in recycling terabytes of rated input from millions of users. 

Myriad startups seize the moment to sell sn**AI**ke oil for right everything: from a toothbrush to fortune-telling (to name decent).

&nbsp;&nbsp;&nbsp;&nbsp;<sup>:hammer_and_wrench:</sup> <sub>Processing global amounts of data in real-time, finding patterns there; on-the-fly video recognition and filtering; routine translation and text generation.</sub>\
&nbsp;&nbsp;&nbsp;&nbsp;<sup>üßë‚Äçüî¨</sup> <sub>Math, physics, and linguistics R&D (as "neural" networks, quantum mechanics, stochastic models)</sub>

## Appendix 1/1. Preceding AI tides

Grunting "again"<sup>:top:</sup> prompts me to reminisce about other AI booms (impromptu and without the wiki). I skip old fiction (Timber Intelligence of Pinocchio and  a bit more scientific), the times when man humanized mechanical or electrical breakthroughs, and would resume on the digital era.

### 1950s - The crucial IT decade ever

Energized racks of metals, glass, and vacuum replaced hives of [handmade calculations](https://commons.wikimedia.org/wiki/File:Human_computers_-_Dryden.jpg#/media/File:Human_computers_-_Dryden.jpg).<sup>üí°</sup> Innovative mathematicians devised the realm and craft of **software** from the ground up and right before one's eyes. 

The leap in hardware and programming could surpass the wildest sci-fi, and two letters could suggest that processors will soon be peers of human brains.

<details>
<summary><ins>&nbsp;These two letters were <b>not</b> <mark>AI</mark> but ...&nbsp;</ins></summary>
  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;... `IF`.

> High-level languages, FORTRAN or COBOL, described algorithms close to usual English, and the **IF** statement introduced the feeling of human doubt and decision-making.

\__________________________________________ 
</details>

&nbsp;&nbsp;&nbsp;&nbsp;<sup>üí°</sup> <sub>To be pedant: digital computers emerged in 1940s and already in 1950s began shedding vacuum tubes for transistors.</sub>

### Late 1970s

Computers got thinner and gradually spread from science and government tasks to business (with a much greater audience, spectrum of functions, and a bit of private time for amusement). Operating Systems grew into a separate phenomenon. 

Robotics delivered funny androids. Programs could support a kind of console dialog for consulting or entertainment (where some confidently saw sparks of sentience on both ends).

In chess, with its intellectual aura, programs could give winning hints (not for cheat as nowadays but an experiment) that grandmasters couldn't discern and attributed to the abrupt progress of their inferior opponents.<sup>:game_die:</sup>

&nbsp;&nbsp;&nbsp;&nbsp;<sup>:game_die:</sup> <sub>It's AlphaGo in 2023 for another strategy game.</sub>

### Late 1980s - early 1990s

PCs became a folk phenomenon at work and home. Thousands of enthusiasts, fascinated by the might and ease of programming, along with top engineers, which one could hire then for symbolic rates, tried to reanimate AI.

A side-effect of that kick was backyard pseudo-sciences of _inventive problem-solving_.

### ‚åõ Let's recap in 2030s ...

And here we are, when _there will be no (human) programmers in five years&nbsp;_<sup>:one:</sup>. ‚Äî No fear, thanks to AI _you'll have universal high income_&nbsp;<sup>:two:</sup>, and _AI can now make you immortal_&nbsp;<sup>:three:</sup>.

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>:one:</sup> <sub>*Emad Mostaque*, CEO of Stability AI, 2023</sub>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>:two:</sup> <sub>_Elon Musk_ [again], Nov 3, 2023</sub>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>:three:</sup> <sub>_Bernard Marr_, Forbes, Feb 21, 2023 </sub>

\______\
<sub>Images credit: Wiki Commons,  IMLO (learncomputerscienceonline.com)</sub>\
 üîö &nbsp;üåò kyriosity 2023-2024


